{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# Refit  TenorRT Graph Module with Torch-TensorRT\n\nWe are going to demonstrate how a compiled TensorRT Graph Module can be refitted with updated weights.\n\nIn many cases, we frequently update the weights of models, such as applying various LoRA to Stable Diffusion or constant A/B testing of AI products.\nThat poses challenges for TensorRT inference optimizations, as compiling the TensorRT engines takes significant time, making repetitive compilation highly inefficient.\nTorch-TensorRT supports refitting TensorRT graph modules without re-compiling the engine, considerably accelerating the workflow.\n\nIn this tutorial, we are going to walk through\n1. Compiling a PyTorch model to a TensorRT Graph Module\n2. Save and load a graph module\n3. Refit the graph module\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Standard Workflow\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Imports and model definition\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport torch\nimport torch_tensorrt as torch_trt\nimport torchvision.models as models\nfrom torch_tensorrt.dynamo import refit_module_weights\n\nnp.random.seed(0)\ntorch.manual_seed(0)\ninputs = [torch.rand((1, 3, 224, 224)).to(\"cuda\")]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Compile the module for the first time and save it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(pretrained=False).eval().to(\"cuda\")\nexp_program = torch.export.export(model, tuple(inputs))\nenabled_precisions = {torch.float}\ndebug = False\nworkspace_size = 20 << 30\nmin_block_size = 0\nuse_python_runtime = False\ntorch_executed_ops = {}\ntrt_gm = torch_trt.dynamo.compile(\n    exp_program,\n    tuple(inputs),\n    use_python_runtime=use_python_runtime,\n    enabled_precisions=enabled_precisions,\n    debug=debug,\n    min_block_size=min_block_size,\n    torch_executed_ops=torch_executed_ops,\n    make_refitable=True,\n)  # Output is a torch.fx.GraphModule\n\n# Save the graph module as an exported program\n# This is only supported when use_python_runtime = False\ntorch_trt.save(trt_gm, \"./compiled.ep\", inputs=inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Refit the module with update model weights\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Create and compile the updated model\nmodel2 = models.resnet18(pretrained=True).eval().to(\"cuda\")\nexp_program2 = torch.export.export(model2, tuple(inputs))\n\n\ncompiled_trt_ep = torch_trt.load(\"./compiled.ep\")\n\n# This returns a new module with updated weights\nnew_trt_gm = refit_module_weights(\n    compiled_module=compiled_trt_ep,\n    new_weight_module=exp_program2,\n    arg_inputs=inputs,\n)\n\n# Check the output\nexpected_outputs, refitted_outputs = exp_program2.module()(*inputs), new_trt_gm(*inputs)\nfor expected_output, refitted_output in zip(expected_outputs, refitted_outputs):\n    assert torch.allclose(\n        expected_output, refitted_output, 1e-2, 1e-2\n    ), \"Refit Result is not correct. Refit failed\"\n\nprint(\"Refit successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Alternative Workflow using Python Runtime\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Currently python runtime does not support engine serialization. So the refitting will be done in the same runtime.\n# This usecase is more useful when you need to switch different weights in the same runtime, such as using Stable Diffusion."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}